{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:20:47.508973Z",
     "start_time": "2025-02-20T08:20:47.495908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load keypoints and labels\n",
    "X = np.load(\"sign_keypoints.npy\")  # Features (hand keypoints)\n",
    "y = np.load(\"sign_labels.npy\")  # Labels (sign classes)\n",
    "\n",
    "print(f\"Loaded {X.shape[0]} samples with {X.shape[1]} features each.\")\n",
    "print(f\"Unique classes: {np.unique(y)}\")"
   ],
   "id": "a3198e8d60c6364c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 105420 samples with 63 features each.\n",
      "Unique classes: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h'\n",
      " 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:20:52.823040Z",
     "start_time": "2025-02-20T08:20:52.812690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Reshape X to fit LSTM (sequence length = 1 since each frame is independent)\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])  # Shape: (samples, sequence_length, features)\n",
    "\n",
    "# Encode labels to numbers (A → 0, B → 1, ..., Z → 25)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# One-hot encode labels for training\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y_categorical.shape}\")\n"
   ],
   "id": "70fd199cc3cc054",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (105420, 1, 63), y shape: (105420, 36)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:21:20.652807Z",
     "start_time": "2025-02-20T08:21:20.627626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=False, input_shape=(1, X.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')  # Output layer with softmax\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ],
   "id": "38b010d61861448c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_3\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_5 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │        \u001B[38;5;34m32,768\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m36\u001B[0m)             │         \u001B[38;5;34m1,188\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,188</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m36,036\u001B[0m (140.77 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,036</span> (140.77 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m36,036\u001B[0m (140.77 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,036</span> (140.77 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:23:02.723579Z",
     "start_time": "2025-02-20T08:21:29.193379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "history = model.fit(X, y_categorical, epochs=20, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"asl_sign_language_model.h5\")\n",
    "\n",
    "print(\"✅ Model trained and saved as 'asl_sign_language_model.h5'\")\n"
   ],
   "id": "b28f5387b35206f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 829us/step - accuracy: 0.0637 - loss: 3.2806 - val_accuracy: 0.0000e+00 - val_loss: 6.4605\n",
      "Epoch 2/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 822us/step - accuracy: 0.0647 - loss: 3.0568 - val_accuracy: 0.0000e+00 - val_loss: 8.6044\n",
      "Epoch 3/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 852us/step - accuracy: 0.0645 - loss: 3.0494 - val_accuracy: 0.0000e+00 - val_loss: 10.7153\n",
      "Epoch 4/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 863us/step - accuracy: 0.0672 - loss: 3.0491 - val_accuracy: 0.0000e+00 - val_loss: 12.8164\n",
      "Epoch 5/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 872us/step - accuracy: 0.0666 - loss: 3.0492 - val_accuracy: 0.0000e+00 - val_loss: 14.8406\n",
      "Epoch 6/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 890us/step - accuracy: 0.0643 - loss: 3.0510 - val_accuracy: 0.0000e+00 - val_loss: 16.4714\n",
      "Epoch 7/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 885us/step - accuracy: 0.0663 - loss: 3.0501 - val_accuracy: 0.0000e+00 - val_loss: 17.4263\n",
      "Epoch 8/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 884us/step - accuracy: 0.0656 - loss: 3.0482 - val_accuracy: 0.0000e+00 - val_loss: 17.9664\n",
      "Epoch 9/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 878us/step - accuracy: 0.0634 - loss: 3.0507 - val_accuracy: 0.0000e+00 - val_loss: 18.3279\n",
      "Epoch 10/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 882us/step - accuracy: 0.0658 - loss: 3.0494 - val_accuracy: 0.0000e+00 - val_loss: 18.5939\n",
      "Epoch 11/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 883us/step - accuracy: 0.0649 - loss: 3.0480 - val_accuracy: 0.0000e+00 - val_loss: 18.8046\n",
      "Epoch 12/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 884us/step - accuracy: 0.0634 - loss: 3.0460 - val_accuracy: 0.0000e+00 - val_loss: 18.9787\n",
      "Epoch 13/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 884us/step - accuracy: 0.0638 - loss: 3.0495 - val_accuracy: 0.0000e+00 - val_loss: 19.1253\n",
      "Epoch 14/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 881us/step - accuracy: 0.0644 - loss: 3.0469 - val_accuracy: 0.0000e+00 - val_loss: 19.2540\n",
      "Epoch 15/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 889us/step - accuracy: 0.0653 - loss: 3.0481 - val_accuracy: 0.0000e+00 - val_loss: 19.3671\n",
      "Epoch 16/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 886us/step - accuracy: 0.0642 - loss: 3.0500 - val_accuracy: 0.0000e+00 - val_loss: 19.4681\n",
      "Epoch 17/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 883us/step - accuracy: 0.0642 - loss: 3.0509 - val_accuracy: 0.0000e+00 - val_loss: 19.5591\n",
      "Epoch 18/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 891us/step - accuracy: 0.0675 - loss: 3.0510 - val_accuracy: 0.0000e+00 - val_loss: 19.6447\n",
      "Epoch 19/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 882us/step - accuracy: 0.0645 - loss: 3.0490 - val_accuracy: 0.0000e+00 - val_loss: 19.7191\n",
      "Epoch 20/20\n",
      "\u001B[1m5271/5271\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 901us/step - accuracy: 0.0635 - loss: 3.0506 - val_accuracy: 0.0000e+00 - val_loss: 19.7911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained and saved as 'asl_sign_language_model.h5'\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:25:25.831784Z",
     "start_time": "2025-02-20T08:25:25.795110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Attention, LayerNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "# Define learning rate schedule\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=0.001, decay_steps=1000, decay_rate=0.9, staircase=True)\n",
    "\n",
    "# Define the upgraded LSTM model\n",
    "model = Sequential([\n",
    "    # First BiLSTM Layer\n",
    "    Bidirectional(LSTM(256, return_sequences=True, kernel_regularizer=l2(0.001))),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Second BiLSTM Layer\n",
    "    Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.001))),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Attention Mechanism\n",
    "    Attention(),\n",
    "\n",
    "    # Third LSTM Layer (Single Direction)\n",
    "    LSTM(64, return_sequences=False, kernel_regularizer=l2(0.001)),\n",
    "    LayerNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Dense Layers with Swish Activation\n",
    "    Dense(128, activation='swish', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='swish', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Output Layer\n",
    "    Dense(y_categorical.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with a learning rate schedule\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ],
   "id": "cd0a29b45546fa87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_4\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (\u001B[38;5;33mBidirectional\u001B[0m) │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001B[38;5;33mDropout\u001B[0m)            │ ?                      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001B[38;5;33mBidirectional\u001B[0m) │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001B[38;5;33mDropout\u001B[0m)            │ ?                      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_1 (\u001B[38;5;33mAttention\u001B[0m)         │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (\u001B[38;5;33mLSTM\u001B[0m)                   │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "│ (\u001B[38;5;33mLayerNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001B[38;5;33mDropout\u001B[0m)            │ ?                      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001B[38;5;33mDense\u001B[0m)                 │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001B[38;5;33mDropout\u001B[0m)            │ ?                      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001B[38;5;33mDense\u001B[0m)                │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001B[38;5;33mDropout\u001B[0m)            │ ?                      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001B[38;5;33mDense\u001B[0m)                │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:27:47.883773Z",
     "start_time": "2025-02-20T08:26:38.103083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load existing model\n",
    "model = tf.keras.models.load_model(\"asl_sign_language_model_v2.h5\")\n",
    "\n",
    "# Load dataset\n",
    "X_train = np.load(\"sign_keypoints.npy\")\n",
    "y_train = np.load(\"sign_labels_encoded.npy\")\n",
    "\n",
    "# Reshape input for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))  # (samples, sequence_length, features)\n",
    "\n",
    "# Compile the model again (optional)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train for additional epochs\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save(\"asl_sign_language_model_v3.h5\")\n",
    "\n",
    "print(\"✅ Model fine-tuned and saved as 'asl_sign_language_model_v2.h5'\")\n"
   ],
   "id": "c24865487ba7a8d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 1ms/step - accuracy: 0.0644 - loss: 3.0490 - val_accuracy: 0.0000e+00 - val_loss: 21.8305\n",
      "Epoch 2/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 966us/step - accuracy: 0.0668 - loss: 3.0488 - val_accuracy: 0.0000e+00 - val_loss: 21.8326\n",
      "Epoch 3/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 969us/step - accuracy: 0.0652 - loss: 3.0495 - val_accuracy: 0.0000e+00 - val_loss: 21.8344\n",
      "Epoch 4/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 983us/step - accuracy: 0.0636 - loss: 3.0479 - val_accuracy: 0.0000e+00 - val_loss: 21.8358\n",
      "Epoch 5/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0663 - loss: 3.0489 - val_accuracy: 0.0000e+00 - val_loss: 21.8388\n",
      "Epoch 6/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 988us/step - accuracy: 0.0653 - loss: 3.0495 - val_accuracy: 0.0000e+00 - val_loss: 21.8410\n",
      "Epoch 7/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 998us/step - accuracy: 0.0641 - loss: 3.0510 - val_accuracy: 0.0000e+00 - val_loss: 21.8433\n",
      "Epoch 8/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0665 - loss: 3.0511 - val_accuracy: 0.0000e+00 - val_loss: 21.8454\n",
      "Epoch 9/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0648 - loss: 3.0482 - val_accuracy: 0.0000e+00 - val_loss: 21.8469\n",
      "Epoch 10/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0648 - loss: 3.0519 - val_accuracy: 0.0000e+00 - val_loss: 21.8493\n",
      "Epoch 11/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0655 - loss: 3.0494 - val_accuracy: 0.0000e+00 - val_loss: 21.8514\n",
      "Epoch 12/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0651 - loss: 3.0499 - val_accuracy: 0.0000e+00 - val_loss: 21.8537\n",
      "Epoch 13/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0648 - loss: 3.0497 - val_accuracy: 0.0000e+00 - val_loss: 21.8561\n",
      "Epoch 14/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0659 - loss: 3.0489 - val_accuracy: 0.0000e+00 - val_loss: 21.8585\n",
      "Epoch 15/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0643 - loss: 3.0507 - val_accuracy: 0.0000e+00 - val_loss: 21.8609\n",
      "Epoch 16/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0652 - loss: 3.0518 - val_accuracy: 0.0000e+00 - val_loss: 21.8635\n",
      "Epoch 17/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0650 - loss: 3.0482 - val_accuracy: 0.0000e+00 - val_loss: 21.8645\n",
      "Epoch 18/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0665 - loss: 3.0490 - val_accuracy: 0.0000e+00 - val_loss: 21.8672\n",
      "Epoch 19/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0651 - loss: 3.0510 - val_accuracy: 0.0000e+00 - val_loss: 21.8695\n",
      "Epoch 20/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0644 - loss: 3.0486 - val_accuracy: 0.0000e+00 - val_loss: 21.8716\n",
      "Epoch 21/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0659 - loss: 3.0456 - val_accuracy: 0.0000e+00 - val_loss: 21.8730\n",
      "Epoch 22/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0654 - loss: 3.0489 - val_accuracy: 0.0000e+00 - val_loss: 21.8759\n",
      "Epoch 23/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0649 - loss: 3.0483 - val_accuracy: 0.0000e+00 - val_loss: 21.8782\n",
      "Epoch 24/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0643 - loss: 3.0492 - val_accuracy: 0.0000e+00 - val_loss: 21.8805\n",
      "Epoch 25/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0655 - loss: 3.0474 - val_accuracy: 0.0000e+00 - val_loss: 21.8826\n",
      "Epoch 26/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0662 - loss: 3.0497 - val_accuracy: 0.0000e+00 - val_loss: 21.8847\n",
      "Epoch 27/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0657 - loss: 3.0492 - val_accuracy: 0.0000e+00 - val_loss: 21.8877\n",
      "Epoch 28/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0661 - loss: 3.0494 - val_accuracy: 0.0000e+00 - val_loss: 21.8892\n",
      "Epoch 29/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0640 - loss: 3.0482 - val_accuracy: 0.0000e+00 - val_loss: 21.8909\n",
      "Epoch 30/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0655 - loss: 3.0484 - val_accuracy: 0.0000e+00 - val_loss: 21.8937\n",
      "Epoch 31/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0650 - loss: 3.0500 - val_accuracy: 0.0000e+00 - val_loss: 21.8955\n",
      "Epoch 32/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0661 - loss: 3.0481 - val_accuracy: 0.0000e+00 - val_loss: 21.8976\n",
      "Epoch 33/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0668 - loss: 3.0471 - val_accuracy: 0.0000e+00 - val_loss: 21.8990\n",
      "Epoch 34/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0669 - loss: 3.0465 - val_accuracy: 0.0000e+00 - val_loss: 21.9014\n",
      "Epoch 35/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0655 - loss: 3.0503 - val_accuracy: 0.0000e+00 - val_loss: 21.9046\n",
      "Epoch 36/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0644 - loss: 3.0510 - val_accuracy: 0.0000e+00 - val_loss: 21.9072\n",
      "Epoch 37/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0649 - loss: 3.0471 - val_accuracy: 0.0000e+00 - val_loss: 21.9086\n",
      "Epoch 38/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0651 - loss: 3.0481 - val_accuracy: 0.0000e+00 - val_loss: 21.9108\n",
      "Epoch 39/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0648 - loss: 3.0493 - val_accuracy: 0.0000e+00 - val_loss: 21.9129\n",
      "Epoch 40/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0651 - loss: 3.0504 - val_accuracy: 0.0000e+00 - val_loss: 21.9149\n",
      "Epoch 41/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0671 - loss: 3.0498 - val_accuracy: 0.0000e+00 - val_loss: 21.9177\n",
      "Epoch 42/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0651 - loss: 3.0517 - val_accuracy: 0.0000e+00 - val_loss: 21.9206\n",
      "Epoch 43/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0659 - loss: 3.0467 - val_accuracy: 0.0000e+00 - val_loss: 21.9214\n",
      "Epoch 44/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0646 - loss: 3.0502 - val_accuracy: 0.0000e+00 - val_loss: 21.9243\n",
      "Epoch 45/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0674 - loss: 3.0483 - val_accuracy: 0.0000e+00 - val_loss: 21.9252\n",
      "Epoch 46/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0656 - loss: 3.0486 - val_accuracy: 0.0000e+00 - val_loss: 21.9277\n",
      "Epoch 47/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0672 - loss: 3.0465 - val_accuracy: 0.0000e+00 - val_loss: 21.9296\n",
      "Epoch 48/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0649 - loss: 3.0510 - val_accuracy: 0.0000e+00 - val_loss: 21.9328\n",
      "Epoch 49/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0638 - loss: 3.0502 - val_accuracy: 0.0000e+00 - val_loss: 21.9341\n",
      "Epoch 50/50\n",
      "\u001B[1m1318/1318\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.0650 - loss: 3.0505 - val_accuracy: 0.0000e+00 - val_loss: 21.9381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model fine-tuned and saved as 'asl_sign_language_model_v2.h5'\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:19:59.815565Z",
     "start_time": "2025-02-20T08:19:59.545103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy Over Time')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss Over Time')\n",
    "plt.show()\n"
   ],
   "id": "c0c05da73dd1dee",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Plot training & validation accuracy\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mhistory\u001B[49m\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining Accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValidation Accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpochs\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:20:08.500684Z",
     "start_time": "2025-02-20T08:20:08.482654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, Bidirectional, LayerNormalization,\n",
    "    MultiHeadAttention, Add, SpatialDropout1D\n",
    ")\n",
    "from tensorflow.keras.optimizers.schedules import CyclicalLearningRate\n",
    "\n",
    "# Cyclic Learning Rate Schedule (Smarter LR Adjustment)\n",
    "clr = CyclicalLearningRate(\n",
    "    initial_learning_rate=1e-5,\n",
    "    maximal_learning_rate=5e-4,\n",
    "    step_size=2000,\n",
    "    scale_fn=lambda x: 0.5 * (1 + tf.math.cos(x * 3.1416))\n",
    ")\n",
    "\n",
    "# Model Input Shape\n",
    "input_layer = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "# 🔥 BiLSTM Base Layer (Context Extraction)\n",
    "x = Bidirectional(LSTM(256, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.0001)))(input_layer)\n",
    "x = LayerNormalization()(x)\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "# 🔥 Multi-Head Self-Attention (Focuses on Important Features)\n",
    "attention = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "x = Add()([x, attention])  # Residual Connection\n",
    "x = LayerNormalization()(x)\n",
    "\n",
    "# 🔥 Second BiLSTM Layer (Deeper Temporal Understanding)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.0001)))(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "# 🔥 Final LSTM Layer (Feature Compression)\n",
    "x = LSTM(64, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "x = LayerNormalization()(x)\n",
    "\n",
    "# 🔥 Dense Layers with Swish Activation\n",
    "x = Dense(128, activation='swish')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='swish')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Output Layer (Softmax for Classification)\n",
    "output_layer = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "\n",
    "# Define & Compile Model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=clr, clipnorm=1.0),  # Adaptive Gradient Clipping\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n"
   ],
   "id": "f39eadf3451a2f3f",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CyclicalLearningRate' from 'tensorflow.keras.optimizers.schedules' (C:\\Users\\PC\\PycharmProjects\\tstai\\.venv\\Lib\\site-packages\\keras\\_tf_keras\\keras\\optimizers\\schedules\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 7\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Input, LSTM, Dense, Dropout, Bidirectional, LayerNormalization,\n\u001B[0;32m      5\u001B[0m     MultiHeadAttention, Add, SpatialDropout1D\n\u001B[0;32m      6\u001B[0m )\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mschedules\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CyclicalLearningRate\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Cyclic Learning Rate Schedule (Smarter LR Adjustment)\u001B[39;00m\n\u001B[0;32m     10\u001B[0m clr \u001B[38;5;241m=\u001B[39m CyclicalLearningRate(\n\u001B[0;32m     11\u001B[0m     initial_learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m,\n\u001B[0;32m     12\u001B[0m     maximal_learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5e-4\u001B[39m,\n\u001B[0;32m     13\u001B[0m     step_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2000\u001B[39m,\n\u001B[0;32m     14\u001B[0m     scale_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mcos(x \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m3.1416\u001B[39m))\n\u001B[0;32m     15\u001B[0m )\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'CyclicalLearningRate' from 'tensorflow.keras.optimizers.schedules' (C:\\Users\\PC\\PycharmProjects\\tstai\\.venv\\Lib\\site-packages\\keras\\_tf_keras\\keras\\optimizers\\schedules\\__init__.py)"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
